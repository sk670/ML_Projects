{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2809f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "795607b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f435cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb560cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7608    1\n",
       "7609    1\n",
       "7610    1\n",
       "7611    1\n",
       "7612    1\n",
       "Name: target, Length: 7613, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = train.iloc[:,-1] \n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8566fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "70a4f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8dff0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "text=[]\n",
    "for comment in train.loc[:,'text']:\n",
    "    comment = re.sub(r'(.)1+', r'1', comment)\n",
    "    comment = re.sub('((http:\\.+)|(www.[^s]+))','',comment) \n",
    "    comment=re.sub('[^a-zA-Z]',' ',comment)\n",
    "    comment=comment.lower()\n",
    "    comment=comment.split()\n",
    "    text=text+comment\n",
    "    comment=[wnl.lemmatize(word) for word in comment if word not in set(stopwords.words('english'))]\n",
    "    comment=' '.join(comment)\n",
    "    corpus.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "54ad9c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deed reason earthquake may allah forgive u'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa171119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fd = FreqDist()\n",
    "for word in text:\n",
    "    fd[word]+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "41f775be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'t': 5315, 'co': 4741, 'http': 4309, 'the': 3286, 'a': 2307, 'in': 1991, 'to': 1952, 'i': 1876, 'of': 1833, 'and': 1426, ...})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "377f4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_values = list(fd.values())\n",
    "fd_values.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "df13bee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22027"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0583f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for top 200 words 48.9223372165985% of data\n",
      "for top 400 words 56.280381321015746% of data\n",
      "for top 600 words 61.5299711968067% of data\n",
      "for top 800 words 65.4520438171413% of data\n",
      "for top 1000 words 68.36411469870045% of data\n",
      "for top 1200 words 70.65400636543012% of data\n",
      "for top 1400 words 72.53037187114919% of data\n",
      "for top 1600 words 74.09300180681448% of data\n",
      "for top 1800 words 75.39859537183335% of data\n",
      "for top 2000 words 76.54845513581348% of data\n",
      "for top 2200 words 77.56828473581953% of data\n",
      "for top 2400 words 78.47547192633641% of data\n",
      "for top 2600 words 79.28135654724555% of data\n",
      "for top 2800 words 80.03734587267628% of data\n",
      "for top 3000 words 80.77519145429667% of data\n",
      "for top 3200 words 81.37998291464125% of data\n",
      "for top 3400 words 81.98477437498582% of data\n",
      "for top 3600 words 82.5895658353304% of data\n",
      "for top 3800 words 83.09532269404356% of data\n",
      "for top 4000 words 83.548916289302% of data\n",
      "for top 4200 words 84.00250988456042% of data\n",
      "for top 4400 words 84.45610347981886% of data\n",
      "for top 4600 words 84.90969707507729% of data\n",
      "for top 4800 words 85.30659147092842% of data\n",
      "for top 5000 words 85.60898720110072% of data\n",
      "for top 5200 words 85.91138293127301% of data\n",
      "for top 5400 words 86.21377866144529% of data\n",
      "for top 5600 words 86.5161743916176% of data\n",
      "for top 5800 words 86.81857012178989% of data\n",
      "for top 6000 words 87.12096585196217% of data\n",
      "for top 6200 words 87.42336158213446% of data\n",
      "for top 6400 words 87.72575731230675% of data\n",
      "for top 6600 words 88.02815304247903% of data\n",
      "for top 6800 words 88.33054877265133% of data\n",
      "for top 7000 words 88.63294450282362% of data\n",
      "for top 7200 words 88.79094627183865% of data\n",
      "for top 7400 words 88.94214413692478% of data\n",
      "for top 7600 words 89.09334200201093% of data\n",
      "for top 7800 words 89.24453986709707% of data\n",
      "for top 8000 words 89.39573773218322% of data\n",
      "for top 8200 words 89.54693559726937% of data\n",
      "for top 8400 words 89.69813346235551% of data\n",
      "for top 8600 words 89.84933132744166% of data\n",
      "for top 8800 words 90.00052919252781% of data\n",
      "for top 9000 words 90.15172705761395% of data\n",
      "for top 9200 words 90.30292492270009% of data\n",
      "for top 9400 words 90.45412278778625% of data\n",
      "for top 9600 words 90.60532065287238% of data\n",
      "for top 9800 words 90.75651851795853% of data\n",
      "for top 10000 words 90.90771638304467% of data\n",
      "for top 10200 words 91.05891424813082% of data\n",
      "for top 10400 words 91.21011211321695% of data\n",
      "for top 10600 words 91.36130997830311% of data\n",
      "for top 10800 words 91.51250784338924% of data\n",
      "for top 11000 words 91.66370570847539% of data\n",
      "for top 11200 words 91.81490357356155% of data\n",
      "for top 11400 words 91.96610143864768% of data\n",
      "for top 11600 words 92.11729930373383% of data\n",
      "for top 11800 words 92.26849716881998% of data\n",
      "for top 12000 words 92.41969503390612% of data\n",
      "for top 12200 words 92.57089289899227% of data\n",
      "for top 12400 words 92.72209076407842% of data\n",
      "for top 12600 words 92.87328862916455% of data\n",
      "for top 12800 words 93.02448649425071% of data\n",
      "for top 13000 words 93.17568435933684% of data\n",
      "for top 13200 words 93.32688222442299% of data\n",
      "for top 13400 words 93.47808008950913% of data\n",
      "for top 13600 words 93.62927795459528% of data\n",
      "for top 13800 words 93.78047581968143% of data\n",
      "for top 14000 words 93.93167368476757% of data\n",
      "for top 14200 words 94.08287154985372% of data\n",
      "for top 14400 words 94.23406941493985% of data\n",
      "for top 14600 words 94.38526728002601% of data\n",
      "for top 14800 words 94.53646514511215% of data\n",
      "for top 15000 words 94.68766301019829% of data\n",
      "for top 15200 words 94.83886087528444% of data\n",
      "for top 15400 words 94.99005874037059% of data\n",
      "for top 15600 words 95.14125660545673% of data\n",
      "for top 15800 words 95.29245447054288% of data\n",
      "for top 16000 words 95.44365233562903% of data\n",
      "for top 16200 words 95.59485020071517% of data\n",
      "for top 16400 words 95.74604806580132% of data\n",
      "for top 16600 words 95.89724593088745% of data\n",
      "for top 16800 words 96.0484437959736% of data\n",
      "for top 17000 words 96.19964166105974% of data\n",
      "for top 17200 words 96.35083952614589% of data\n",
      "for top 17400 words 96.50203739123204% of data\n",
      "for top 17600 words 96.65323525631818% of data\n",
      "for top 17800 words 96.80443312140432% of data\n",
      "for top 18000 words 96.95563098649048% of data\n",
      "for top 18200 words 97.10682885157662% of data\n",
      "for top 18400 words 97.25802671666276% of data\n",
      "for top 18600 words 97.40922458174892% of data\n",
      "for top 18800 words 97.56042244683505% of data\n",
      "for top 19000 words 97.7116203119212% of data\n",
      "for top 19200 words 97.86281817700734% of data\n",
      "for top 19400 words 98.01401604209349% of data\n",
      "for top 19600 words 98.16521390717963% of data\n",
      "for top 19800 words 98.31641177226578% of data\n",
      "for top 20000 words 98.46760963735191% of data\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "s1=sum(fqd_values)\n",
    "iteration =1 \n",
    "l=[]\n",
    "for i in range(0,20000,200): \n",
    "    s=s+sum(fqd_values[i:i+200])\n",
    "    print(f'for top {i+200} words {(s/s1)*100}% of data')\n",
    "    l.append((s/s1)*100) \n",
    "    iteration+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "43874d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=4000)\n",
    "train = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bbe981f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 4000)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e4266873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just happened terrible car crash',\n",
       " 'Heard  earthquake different city  stay safe everyone ',\n",
       " 'forest fire spot pond  goose fleeing across street  I cannot save',\n",
       " 'Apocalypse lighting   Spokane  wildfire',\n",
       " 'Typhoon Soudelor kill    China Taiwan']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1 = []\n",
    "for st in test.loc[:,'text']:  \n",
    "    st = re.sub(r'(.)1+', r'1', st)\n",
    "    st = re.sub('((http:\\.+)|(www.[^s]+))','',st) \n",
    "    st = re.sub('[^a-zA-Z]',' ',st) \n",
    "    st = st.split(' ')\n",
    "    st = [wl.lemmatize(i) for i in st if i not in set(stopwords.words('english'))] \n",
    "    st = ' '.join(st) \n",
    "    tweets1.append(st)  \n",
    "tweets1[0:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7f65cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tfidf.transform(tweets1) \n",
    "test = test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0dc09be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d789a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7064294915543791"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr,train,Y_train).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4dfba25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(train,Y_train)\n",
    "Y_prediction = lr.predict(test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "45bdb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2b54c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['target']=Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "842ee79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb25629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
